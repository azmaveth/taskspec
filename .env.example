# TaskSpec Configuration
# Copy this file to .env and modify as needed

# LLM Provider Settings
# Choose from: "ollama", "openai", "anthropic", "cohere"
LLM_PROVIDER=ollama

# LLM Model
# This varies by provider:
# - ollama: "athene-v2" (default)
# - openai: "gpt-4o"
# - anthropic: "claude-3-opus-20240229"
# - cohere: "command-r"
LLM_MODEL=athene-v2

# API Keys (required for hosted providers)
OPENAI_API_KEY=
ANTHROPIC_API_KEY=
COHERE_API_KEY=
BRAVE_API_KEY=

# Output settings
# Directory where analysis results will be saved
OUTPUT_DIRECTORY=output

# Search settings
MAX_SEARCH_RESULTS=5

# Analysis settings
# Enable (1) or disable (0) multi-step analysis
MULTI_STEP_ENABLED=1
# Enable (1) or disable (0) validation step
VALIDATION_ENABLED=1
# Maximum number of validation iterations
MAX_VALIDATION_ITERATIONS=3

# Cache settings
# Enable (1) or disable (0) caching
CACHE_ENABLED=1
# Cache type: "memory" or "disk"
CACHE_TYPE=disk
# Cache TTL in seconds (24 hours)
CACHE_TTL=86400
# Custom cache directory path (optional)
CACHE_PATH=

# Project conventions
# Path to a file containing coding standards and design preferences (optional)
CONVENTIONS_FILE=
